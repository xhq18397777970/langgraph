from operator import add
from dotenv import load_dotenv
from typing import TypedDict, Annotated
from langchain_core.messages import AnyMessage
from langgraph.graph import START, END
from langgraph.graph import StateGraph
from langchain_core.messages import HumanMessage,AIMessage
from langgraph.checkpoint.memory import MemorySaver
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.model_config import get_deepseek_model
from langchain_mcp_adapters.client import MultiServerMCPClient
import asyncio
from langgraph.prebuilt  import create_react_agent
from langchain_core.tools import StructuredTool
from pydantic import BaseModel
from typing import Any, Dict
# å®šä¹‰æ—¥å¿—å‡½æ•°
def get_stream_writer():
    """ç®€å•çš„æµå¼è¾“å‡ºå†™å…¥å™¨"""
    def writer(data):
        if isinstance(data, dict):
            print(f"ğŸ“Š {data}")
        else:
            print(f"ğŸ”” {data}")
    return writer

def create_sync_tool_wrapper(async_tool):
    """åˆ›å»ºåŒæ­¥å·¥å…·åŒ…è£…å™¨ï¼Œå°†å¼‚æ­¥ MCP å·¥å…·è½¬æ¢ä¸ºåŒæ­¥å·¥å…·"""
    
    def sync_func(**kwargs):
        """åŒæ­¥åŒ…è£…å‡½æ•°ï¼Œä½¿ç”¨ asyncio.run è°ƒç”¨å¼‚æ­¥å·¥å…·"""
        try:
            # è°ƒç”¨å¼‚æ­¥å·¥å…·çš„ coroutine å‡½æ•°
            result = asyncio.run(async_tool.coroutine(**kwargs))
            return result
        except Exception as e:
            print(f"ğŸ” [DEBUG] åŒæ­¥åŒ…è£…å™¨æ‰§è¡Œå¼‚å¸¸: {e}")
            raise e
    
    # åˆ›å»ºæ–°çš„åŒæ­¥ StructuredTool
    sync_tool = StructuredTool.from_function(
        func=sync_func,
        name=async_tool.name,
        description=async_tool.description,
        args_schema=async_tool.args_schema,
        return_direct=getattr(async_tool, 'return_direct', False)
    )
    
    print(f"ğŸ” [DEBUG] åˆ›å»ºåŒæ­¥å·¥å…·åŒ…è£…å™¨: {async_tool.name}")
    return sync_tool

def convert_async_tools_to_sync(async_tools):
    """å°†å¼‚æ­¥å·¥å…·åˆ—è¡¨è½¬æ¢ä¸ºåŒæ­¥å·¥å…·åˆ—è¡¨"""
    sync_tools = []
    for tool in async_tools:
        if hasattr(tool, 'coroutine') and tool.coroutine is not None:
            # è¿™æ˜¯ä¸€ä¸ªå¼‚æ­¥å·¥å…·ï¼Œéœ€è¦åŒ…è£…
            sync_tool = create_sync_tool_wrapper(tool)
            sync_tools.append(sync_tool)
            print(f"ğŸ” [DEBUG] è½¬æ¢å¼‚æ­¥å·¥å…·: {tool.name} -> åŒæ­¥å·¥å…·")
        else:
            # è¿™å·²ç»æ˜¯åŒæ­¥å·¥å…·ï¼Œç›´æ¥ä½¿ç”¨
            sync_tools.append(tool)
            print(f"ğŸ” [DEBUG] ä¿æŒåŒæ­¥å·¥å…·: {tool.name}")
    
    return sync_tools

load_dotenv()

# ä¿®æ­£ï¼šnodes åº”è¯¥ä¸æ¨¡å‹è¿”å›çš„ç±»å‹ä¸€è‡´
nodes = ["domain", "joke", "chinese", "other"]
llm = get_deepseek_model()

#è¿™é‡Œçš„ add æ“ä½œç¬¦æ„å‘³ç€ï¼š
#æ–°è¿”å›çš„ messages ä¼šè¿½åŠ åˆ°ç°æœ‰çš„æ¶ˆæ¯åˆ—è¡¨ä¸­
#å¿…é¡»è¿”å›æ ‡å‡†çš„æ¶ˆæ¯å¯¹è±¡ï¼ˆBaseMessage å¯¹è±¡ï¼Œå¦‚AIMessageã€HumanMessageï¼‰ï¼Œä¸èƒ½æ˜¯çº¯å­—ç¬¦ä¸²
class State(TypedDict):
    messages: Annotated[list[AnyMessage], add]
    type: str

def supervisor_node(state: State):
    writer = get_stream_writer()
    writer({">>> supervisor_node"})
    
    prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œè´Ÿè´£å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å°†ä»»åŠ¡åˆ†ç»™å…¶ä»–Agentæ‰§è¡Œã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å’ŒåŸŸåç›¸å…³çš„ã€ä¸æ—¥å¿—æŸ¥è¯¢ï¼ˆQPSã€å¸¦å®½å†å²æ•°æ®ï¼‰ï¼Œé‚£å°±è¿”å›domainã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›è®²ä¸€ä¸ªç¬‘è¯ï¼Œé‚£å°±è¿”å›jokeã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›è¿›è¡Œä¸­æ–‡çš„å¥å­åˆ†æï¼Œé‚£å°±è¿”å›chineseã€‚
        å¦‚æœæ˜¯å…¶ä»–çš„é—®é¢˜ï¼Œè¿”å›otherã€‚
        æ³¨æ„ï¼šåªè¿”å›ä¸Šè¿°å››ä¸ªå•è¯ä¸­çš„ä¸€ä¸ªï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–çš„å†…å®¹ã€‚
        """
    
    # ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†æ¶ˆæ¯å†…å®¹
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_content = state["messages"][-1].content
    else:
        user_content = str(state["messages"])
    
    print(f"ç”¨æˆ·é—®é¢˜: {user_content}")
    
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": user_content}
    ]
    
    # å¦‚æœå·²æœ‰typeå±æ€§ä¸”ä¸æ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­æ˜¯å¦å®Œæˆ
    if "type" in state and state["type"] in ["domain", "joke", "chinese", "other"]:
        # ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ
        completion_prompt = f"""
        è¯·åˆ¤æ–­å½“å‰å¯¹è¯æ˜¯å¦å·²ç»å®Œæˆç”¨æˆ·çš„ä»»åŠ¡éœ€æ±‚ã€‚
        
        ç”¨æˆ·åŸå§‹è¯·æ±‚ï¼š
        {state['messages'][0].content if state['messages'] else 'æ— '}
        
        å½“å‰å¯¹è¯å†å²ï¼š
        {[msg.content for msg in state['messages']]}
        
        å½“å‰ä»»åŠ¡ç±»å‹ï¼š{state['type']}
        
        è¯·ä»”ç»†æ£€æŸ¥ç”¨æˆ·åŸå§‹è¯·æ±‚ä¸­æ˜¯å¦åŒ…å«å¤šä¸ªä»»åŠ¡è¦æ±‚ï¼Œç„¶åå›ç­”"å®Œæˆ"æˆ–"æœªå®Œæˆ"ï¼š
        - å¦‚æœç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡è¦æ±‚éƒ½å·²ç»æ»¡è¶³ï¼Œå›ç­”"å®Œæˆ"
        - å¦‚æœç”¨æˆ·è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡è¦æ±‚ï¼Œå›ç­”"æœªå®Œæˆ"
        
        ç‰¹åˆ«æ³¨æ„ï¼šç”¨æˆ·å¯èƒ½åœ¨ä¸€ä¸ªè¯·æ±‚ä¸­è¦æ±‚å¤šä¸ªä»»åŠ¡ã€‚
        """
        
        completion_messages = [
            {"role": "system", "content": completion_prompt}
        ]
        
        completion_response = llm.invoke(completion_messages)
        completion_result = completion_response.content.strip()
        
        writer({"supervisor_step": f"ä»»åŠ¡å®ŒæˆçŠ¶æ€åˆ¤æ–­: {completion_result}"})
        
        if "å®Œæˆ" in completion_result:
            writer({"supervisor_step": f"ä»»åŠ¡å·²å®Œæˆï¼Œæµç¨‹ç»“æŸ"})
            return {"type": END}
        else:
            # åˆ¤æ–­ä¸‹ä¸€æ­¥æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹
            next_step_prompt = f"""
            æ ¹æ®ç”¨æˆ·åŸå§‹è¯·æ±‚å’Œå½“å‰è¿›å±•ï¼Œå†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œå“ªä¸ªå¤„ç†èŠ‚ç‚¹ã€‚
            
            ç”¨æˆ·åŸå§‹è¯·æ±‚ï¼š
            {state['messages'][0].content if state['messages'] else 'æ— '}
            
            å½“å‰å¯¹è¯å†å²ï¼š
            {[msg.content for msg in state['messages']]}
            
            å½“å‰å·²å®Œæˆçš„ä»»åŠ¡ï¼š{state['type']}
            å¯ç”¨èŠ‚ç‚¹ï¼šdomain, joke, chinese, other
            
            è¯·åˆ†æç”¨æˆ·è¿˜æœ‰å“ªäº›ä»»åŠ¡æ²¡æœ‰å®Œæˆï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚
            åªè¿”å›èŠ‚ç‚¹åç§°ï¼ˆdomain/joke/chinese/otherï¼‰
            """
            
            next_step_messages = [
                {"role": "system", "content": next_step_prompt}
            ]
            
            next_step_response = llm.invoke(next_step_messages)
            next_node = next_step_response.content.strip().lower()
            
            # æ‰“å°ä¿¡æ¯è°ƒè¯•
            writer({"supervisor_step": f"å¤§æ¨¡å‹å»ºè®®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {next_node}"})
            
            # ç¡®ä¿è¿”å›çš„èŠ‚ç‚¹åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­
            if next_node not in nodes:
                # å¦‚æœå»ºè®®çš„èŠ‚ç‚¹ä¸åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­ï¼Œé‡æ–°åˆ†æç”¨æˆ·åŸå§‹è¯·æ±‚
                original_request = state['messages'][0].content if state['messages'] else user_content
                writer({"supervisor_step": f"é‡æ–°åˆ†æåŸå§‹è¯·æ±‚: {original_request}"})
                
                # é‡æ–°åˆ†ç±»åŸå§‹è¯·æ±‚
                reclassify_messages = [
                    {"role": "system", "content": prompt},
                    {"role": "user", "content": original_request}
                ]
                reclassify_response = llm.invoke(reclassify_messages)
                next_node = reclassify_response.content.strip().lower()
                writer({"supervisor_step": f"é‡æ–°åˆ†ç±»ç»“æœ: {next_node}"})
            
            # æœ€ç»ˆéªŒè¯èŠ‚ç‚¹æœ‰æ•ˆæ€§
            if next_node not in nodes:
                next_node = "other"  # é»˜è®¤ä½¿ç”¨ other
            
            writer({"supervisor_step": f"ç»§ç»­æ‰§è¡Œ: {next_node}"})
            return {"type": next_node}  # è¿™é‡Œåº”è¯¥è¿”å›èŠ‚ç‚¹åç§°ï¼Œä¸æ˜¯ END
    
    # é¦–æ¬¡æ‰§è¡Œï¼Œè¿›è¡Œä»»åŠ¡åˆ†ç±»
    response = llm.invoke(messages)
    typeRes = response.content.strip().lower()
    writer({"supervisor_step": f"é—®é¢˜åˆ†ç±»ç»“æœ: {typeRes}"})
    
    print(f"æ¨¡å‹è¿”å›ç±»å‹: '{typeRes}'")
    print(f"é¢„å®šä¹‰èŠ‚ç‚¹: {nodes}")
    
    # ä¿®æ­£ï¼šæ£€æŸ¥ç±»å‹æ˜¯å¦åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­
    if typeRes in nodes:
        print(f"âœ… ç±»å‹ '{typeRes}' åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­")
        return {"type": typeRes}
    else:
        print(f"âš ï¸  ç±»å‹ '{typeRes}' ä¸åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­ï¼Œä½¿ç”¨ 'other'")
        return {"type": "other"}
def domain_node(state: State):
    print(">>> domain_node")
    writer = get_stream_writer()
    writer({"node": "domain_node"})
    
    # ä¿®æ­£ï¼šæ­£ç¡®æ„å»ºæ¶ˆæ¯æ ¼å¼
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
    else:
        user_input = str(state["messages"])
    
    system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŸŸåã€æ—¥å¿—æ•°æ®åˆ†æé¢†åŸŸä¸“å®¶ï¼Œæ ¹æ®æä¾›çš„å·¥å…·å®ŒæˆåŸŸåã€æ—¥å¿—æ•°æ®æ£€ç´¢å’Œåˆ†æç›¸å…³çš„åŠŸèƒ½ã€‚
        """
        
    prompts = [
        {"role": "system", "content":system_prompt},
        {"role":"user","content":user_input}
    ]
    
    try:
        #mcpå®¢æˆ·ç«¯ï¼Œç”¨äºè¿æ¥mcpæœåŠ¡
        print("ğŸ” [DEBUG] åˆ›å»º MCP å®¢æˆ·ç«¯...")
        client = MultiServerMCPClient(
            {
                "domain-info-service": {
                    "url": "http://127.0.0.1:10025/sse",
                    "transport": "sse",
                }
            }
        )
        
        #langgraphæ•´ä¸ªå›¾æ˜¯åŒæ­¥çš„ï¼Œéœ€è¦å°†å¼‚æ­¥æ–¹æ³•è½¬ä¸ºåŒæ­¥çš„å®ç°
        print("ğŸ” [DEBUG] è·å– MCP å·¥å…·...")
        async_tools = asyncio.run(client.get_tools())
        
        # æ·»åŠ è¯Šæ–­æ—¥å¿—
        print(f"ğŸ” [DEBUG] è·å–åˆ° {len(async_tools)} ä¸ªå¼‚æ­¥å·¥å…·")
        for i, tool in enumerate(async_tools):
            print(f"ğŸ” [DEBUG] å¼‚æ­¥å·¥å…· {i}: {type(tool).__name__}")
            print(f"ğŸ” [DEBUG] å·¥å…·åç§°: {getattr(tool, 'name', 'Unknown')}")
            if hasattr(tool, 'coroutine'):
                print(f"ğŸ” [DEBUG] å·¥å…·æœ‰ coroutine å±æ€§: {tool.coroutine}")
            if hasattr(tool, 'func'):
                print(f"ğŸ” [DEBUG] å·¥å…· func ç±»å‹: {type(tool.func)}")
        
        # å°†å¼‚æ­¥å·¥å…·è½¬æ¢ä¸ºåŒæ­¥å·¥å…·
        print("ğŸ” [DEBUG] è½¬æ¢å¼‚æ­¥å·¥å…·ä¸ºåŒæ­¥å·¥å…·...")
        sync_tools = convert_async_tools_to_sync(async_tools)
        
        print(f"ğŸ” [DEBUG] è½¬æ¢å®Œæˆï¼Œå¾—åˆ° {len(sync_tools)} ä¸ªåŒæ­¥å·¥å…·")
        for i, tool in enumerate(sync_tools):
            print(f"ğŸ” [DEBUG] åŒæ­¥å·¥å…· {i}: {type(tool).__name__}")
            print(f"ğŸ” [DEBUG] å·¥å…·åç§°: {getattr(tool, 'name', 'Unknown')}")
            if hasattr(tool, 'func') and tool.func is not None:
                print(f"ğŸ” [DEBUG] å·¥å…·æœ‰æœ‰æ•ˆçš„ func: {type(tool.func)}")
            else:
                print(f"ğŸ” [DEBUG] å·¥å…· func ä¸ºç©ºæˆ–æ— æ•ˆ")
        
        print("ğŸ” [DEBUG] åˆ›å»º React Agent...")
        agent = create_react_agent(
            model=llm,
            tools=sync_tools,
        )
        
        writer({"domain_step": "è°ƒç”¨åŸŸåæŸ¥è¯¢å·¥å…·..."})
        
        print("ğŸ” [DEBUG] è°ƒç”¨ Agent...")
        # ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¡®çš„è¾“å…¥æ ¼å¼
        response = agent.invoke({"messages":prompts})
        
        # ä¿®æ­£ï¼šæ­£ç¡®æå–å“åº”å†…å®¹
        if response and "messages" in response and response["messages"]:
            last_message = response["messages"][-1]
            if hasattr(last_message, 'content'):
                result_content = last_message.content
            else:
                result_content = str(last_message)
        else:
            result_content = "åŸŸåæŸ¥è¯¢å®Œæˆ"
            
        writer({"domain_result": result_content})
        
        # ä¿®æ­£ï¼šè¿”å›æ­£ç¡®çš„æ¶ˆæ¯æ ¼å¼
        return {"messages": [AIMessage(content=result_content)], "type": "domain"}
        
    except Exception as e:
        print(f"ğŸ” [DEBUG] å¼‚å¸¸è¯¦æƒ…: {type(e).__name__}: {str(e)}")
        import traceback
        print(f"ğŸ” [DEBUG] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        writer({"error": f"åŸŸåæŸ¥è¯¢å¤±è´¥: {e}"})
        error_msg = f"åŸŸåæŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
        return {"messages": [AIMessage(content=error_msg)], "type": "domain"}

def joke_node(state: State):

    writer({">>> joke_node"})
    
    # æ›´è¯¦ç»†çš„æç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å–œå‰§ç¼–å‰§å’Œç¬‘è¯ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚åˆ›ä½œä¸€ä¸ªç²¾å½©çš„ç¬‘è¯ã€‚
    
    åˆ›ä½œæŒ‡å—ï¼š
    1. ç»“æ„å®Œæ•´ï¼šæœ‰é“ºå«ã€è½¬æŠ˜å’Œç¬‘ç‚¹
    2. è¯­è¨€ç”ŸåŠ¨ï¼šä½¿ç”¨å½¢è±¡çš„è¯­è¨€å’Œé€‚å½“çš„å¤¸å¼ 
    3. è´´è¿‘ç”Ÿæ´»ï¼šä»æ—¥å¸¸ç”Ÿæ´»ä¸­å¯»æ‰¾çµæ„Ÿ
    4. ç§¯æå‘ä¸Šï¼šé¿å…ä½ä¿—ã€æ­§è§†æ€§å†…å®¹
    5. é€‚åº¦åˆ›æ–°ï¼šå¯ä»¥ç»“åˆæ—¶äº‹çƒ­ç‚¹æˆ–æµè¡Œæ–‡åŒ–
    
    å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç¬‘è¯ç±»å‹ï¼ˆå¦‚å†·ç¬‘è¯ã€ç›¸å£°æ®µå­ã€è°éŸ³æ¢—ç­‰ï¼‰ï¼Œè¯·æŒ‰ç…§è¦æ±‚åˆ›ä½œã€‚
    å¦‚æœç”¨æˆ·æåˆ°äº†å…·ä½“çš„å–œå‰§æ¼”å‘˜é£æ ¼ï¼ˆå¦‚éƒ­å¾·çº²ã€å‘¨ç«‹æ³¢ç­‰ï¼‰ï¼Œè¯·æ¨¡ä»¿ç›¸åº”çš„é£æ ¼ã€‚
    ç‰¹åˆ«æ³¨æ„ï¼šé™¤äº†ç”Ÿæˆç¬‘è¯ï¼Œä¸åšå…¶ä»–ä»»ä½•æ¨ç†ä»»åŠ¡ï¼è¾“å…¥æ˜¯è¦æ±‚ï¼Œè¾“å‡ºæ˜¯ç¬‘è¯ï¼
    """
    
    # è·å–ç”¨æˆ·è¾“å…¥
    #state["messages"] å­˜å‚¨äº†æ•´ä¸ªå¯¹è¯å†å²
    #state["messages"][-1] è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ç”¨æˆ·çš„è¾“å…¥ï¼‰
    #é€šè¿‡ .content å±æ€§æå–æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
    
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
        user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n\nè¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚åˆ›ä½œä¸€ä¸ªåˆé€‚çš„ç¬‘è¯ã€‚"
    else:
        user_prompt = "è¯·åˆ›ä½œä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯ï¼Œä¸»é¢˜ä¸é™ã€‚"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    writer({"joke_generation": "å¤§æ¨¡å‹æ­£åœ¨åˆ›ä½œç¬‘è¯..."})
    
    try:
        response = llm.invoke(messages)
        joke_content = response.content.strip()
        
        # ç¡®ä¿ç¬‘è¯å†…å®¹ä¸ä¸ºç©º
        if not joke_content:
            joke_content = "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯åˆ†ä¸æ¸…ä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ï¼Ÿå› ä¸º Oct 31 == Dec 25ï¼"
            
        writer({"generated_joke": joke_content})
        
    except Exception as e:
        writer({"error": f"ç¬‘è¯ç”Ÿæˆå¤±è´¥: {e}"})
        # å¤‡ç”¨ç¬‘è¯
        joke_content = "å¬è¯´æœ‰ä¸ªç¨‹åºå‘˜å»é’“é±¼ï¼Œé’“äº†ä¸€å¤©éƒ½æ²¡é’“åˆ°ã€‚åæ¥ä»–å‘ç°ï¼ŒåŸæ¥ä»–ä¸€ç›´åœ¨è°ƒçš„æ˜¯ debugã€‚ã€‚ã€‚"
    
    #æ‹¿åˆ°å¤§æ¨¡å‹æ€è€ƒç»“æœåï¼Œæ›´æ–°stateçŠ¶æ€
    #å¿…é¡»è¦HumanMessageæ–¹å¼è¿”å›ï¼Œä¸å¯ä»¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    #langchainä¸­æœ‰ä¸åŒæ¶ˆæ¯ç±»å‹ï¼š 
    return {"messages": [AIMessage(content=joke_content)], "type": "joke"}

def chinese_node(state: State):
    print(">>> analyse_node")
    writer = get_stream_writer()
    writer({"node": "chinese_node"})
    # å®é™…åº”è¯¥è°ƒç”¨å¯¹è”ç”ŸæˆAPI
    
    system_prompt="""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­è¨€å¤§å¸ˆï¼Œç”¨äºåˆ†æä¸­æ–‡å¥å­æˆåˆ†ï¼Œè´Ÿè´£ä¸­æ–‡çš„è¯­ä¹‰åˆ†æï¼Œè¾“å‡ºæ‰€æœ‰çš„åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯ã€‚
    ç‰¹åˆ«æ³¨æ„ï¼šé™¤æ­¤ä¹‹å¤–ï¼Œä¸åšä»»ä½•å…¶ä»–çš„æ¨ç†å·¥ä½œï¼
    """
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
        user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n\nè¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚åˆ†æä¸­æ–‡å¥å­æˆåˆ†ã€‚"
    else:
        user_prompt = "è¯·åˆ›ä½œä¸€ä¸ªæœ‰è¶£çš„å¯¹è”ï¼Œä¸»é¢˜ä¸é™ã€‚"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    writer({"chinese_generation": "å¤§æ¨¡å‹æ­£åœ¨åˆ†æå¥å­è¯­æ„"})
    
    try:
        response = llm.invoke(messages)
        chinese_content = response.content.strip()
        
        # ç¡®ä¿å¯¹è”å†…å®¹ä¸ä¸ºç©º
        if not chinese_content:
            chinese_content = "é»˜è®¤å¯¹è”"
            
        writer({"generated_joke": chinese_content})
        
    except Exception as e:
        writer({"error": f"å¯¹è”ç”Ÿæˆå¤±è´¥: {e}"})
        # å¤‡ç”¨ç¬‘è¯
        chinese_content = "å‡†å¤‡å¥½çš„å¯¹è”"
    
    #æ‹¿åˆ°å¤§æ¨¡å‹æ€è€ƒç»“æœåï¼Œæ›´æ–°stateçŠ¶æ€
    #å¿…é¡»è¦HumanMessageæ–¹å¼è¿”å›ï¼Œä¸å¯ä»¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    #langchainä¸­æœ‰ä¸åŒæ¶ˆæ¯ç±»å‹ï¼š
    return {"messages": [AIMessage(content=chinese_content)], "type": "chinese"}

def deeplog_node(state:State):
    print(">>> analyse_node")
    writer = get_stream_writer()
    writer({"node": "deeplog_node"})
    # å®é™…åº”è¯¥è°ƒç”¨å¯¹è”ç”ŸæˆAPI
    
    system_prompt="""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è¯­è¨€å¤§å¸ˆï¼Œç”¨äºåˆ†æä¸­æ–‡å¥å­æˆåˆ†ï¼Œè´Ÿè´£ä¸­æ–‡çš„è¯­ä¹‰åˆ†æï¼Œè¾“å‡ºæ‰€æœ‰çš„åè¯ã€åŠ¨è¯ã€å½¢å®¹è¯ã€å‰¯è¯ã€‚
    ç‰¹åˆ«æ³¨æ„ï¼šé™¤æ­¤ä¹‹å¤–ï¼Œä¸åšä»»ä½•å…¶ä»–çš„æ¨ç†å·¥ä½œï¼
    """
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
        user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n\nè¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚åˆ†æä¸­æ–‡å¥å­æˆåˆ†ã€‚"
    else:
        user_prompt = "è¯·åˆ›ä½œä¸€ä¸ªæœ‰è¶£çš„å¯¹è”ï¼Œä¸»é¢˜ä¸é™ã€‚"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    writer({"deeplog_generation": "å¤§æ¨¡å‹æ­£åœ¨åˆ†æå¥å­è¯­æ„"})
    
    try:
        response = llm.invoke(messages)
        deeplog_content = response.content.strip()
        
        # ç¡®ä¿å¯¹è”å†…å®¹ä¸ä¸ºç©º
        if not deeplog_content:
            deeplog_content = "é»˜è®¤å¯¹è”"
            
        writer({"generated_joke": deeplog_content})
        
    except Exception as e:
        writer({"error": f"å¯¹è”ç”Ÿæˆå¤±è´¥: {e}"})
        # å¤‡ç”¨ç¬‘è¯
        chinese_content = "å‡†å¤‡å¥½çš„å¯¹è”"
    
    #æ‹¿åˆ°å¤§æ¨¡å‹æ€è€ƒç»“æœåï¼Œæ›´æ–°stateçŠ¶æ€
    #å¿…é¡»è¦HumanMessageæ–¹å¼è¿”å›ï¼Œä¸å¯ä»¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    #langchainä¸­æœ‰ä¸åŒæ¶ˆæ¯ç±»å‹ï¼š
    return {"messages": [AIMessage(content=chinese_content)], "type": "chinese"}
def other_node(state: State):
    print(">>> other_node")
    writer = get_stream_writer()
    writer({"node": "other_node"})
    other_response = "æˆ‘ä¸»è¦æ“…é•¿æ—…æ¸¸è§„åˆ’ã€è®²ç¬‘è¯å’Œå¯¹å¯¹è”ï¼Œæ‚¨çš„é—®é¢˜æš‚æ—¶æ— æ³•å›ç­”ã€‚"
    return {"messages": [HumanMessage(content=other_response)], "type": "other"}

def routing_func(state: State):
    print(f"è·¯ç”±å‡½æ•°æ¥æ”¶åˆ°ç±»å‹: {state['type']}")
    
    if state["type"] == "domain":
        return "domain_node"
    elif state["type"] == "joke":
        return "joke_node"
    elif state["type"] == "chinese":
        return "chinese_node"
    elif state["type"] == "other":
        return "other_node"
    elif state["type"] == END:
        return END
    else:
        print(f"âŒ æœªçŸ¥ç±»å‹: {state['type']}ï¼Œè·¯ç”±åˆ° other_node")
        return "other_node"

# æ„å»ºå›¾
builder = StateGraph(State)
builder.add_node("supervisor_node", supervisor_node)
builder.add_node("domain_node", domain_node)
builder.add_node("joke_node", joke_node)
builder.add_node("chinese_node", chinese_node)
builder.add_node("other_node", other_node)

# è®¾ç½®æµç¨‹
builder.add_edge(START, "supervisor_node")

# æ¡ä»¶è·¯ç”±ï¼Œlanggraphæ‰§è¡Œå¼•æ“ï¼Œå¦‚æœè¿”å›å€¼ä¸ºjoke_nodeåˆ™ä¸‹ä¸€ä¸ªæ‰§è¡Œä»»åŠ¡çš„æ˜¯joke_node
builder.add_conditional_edges(
    "supervisor_node",
    routing_func,
    {
        "domain_node": "domain_node",
        "joke_node": "joke_node", 
        "chinese_node": "chinese_node",
        "other_node": "other_node",
        END: END
    }
)

# å„ä¸ªå¤„ç†èŠ‚ç‚¹å®Œæˆåå›åˆ° supervisor_node è¿›è¡Œç»“æœç¡®è®¤
builder.add_edge("domain_node", "supervisor_node")
builder.add_edge("joke_node", "supervisor_node") 
builder.add_edge("chinese_node", "supervisor_node")
builder.add_edge("other_node", "supervisor_node")

checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)

