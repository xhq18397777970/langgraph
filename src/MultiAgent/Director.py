from operator import add
from dotenv import load_dotenv
from typing import TypedDict, Annotated
from langchain_core.messages import AnyMessage
from langgraph.graph import START, END
from langgraph.graph import StateGraph
from langchain_core.messages import HumanMessage,AIMessage
from langgraph.checkpoint.memory import MemorySaver
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.model_config import get_deepseek_model

# å®šä¹‰æ—¥å¿—å‡½æ•°
def get_stream_writer():
    """ç®€å•çš„æµå¼è¾“å‡ºå†™å…¥å™¨"""
    def writer(data):
        if isinstance(data, dict):
            print(f"ğŸ“Š {data}")
        else:
            print(f"ğŸ”” {data}")
    return writer

load_dotenv()

# ä¿®æ­£ï¼šnodes åº”è¯¥ä¸æ¨¡å‹è¿”å›çš„ç±»å‹ä¸€è‡´
nodes = ["travel", "joke", "couplet", "other"]
llm = get_deepseek_model()

#è¿™é‡Œçš„ add æ“ä½œç¬¦æ„å‘³ç€ï¼š
#æ–°è¿”å›çš„ messages ä¼šè¿½åŠ åˆ°ç°æœ‰çš„æ¶ˆæ¯åˆ—è¡¨ä¸­
#å¿…é¡»è¿”å›æ ‡å‡†çš„æ¶ˆæ¯å¯¹è±¡ï¼ˆBaseMessage å¯¹è±¡ï¼Œå¦‚AIMessageã€HumanMessageï¼‰ï¼Œä¸èƒ½æ˜¯çº¯å­—ç¬¦ä¸²
class State(TypedDict):
    messages: Annotated[list[AnyMessage], add]
    type: str

def supervisor_node(state: State):
    print(">>> supervisor_node")
    writer = get_stream_writer()
    writer({"node": "supervisor_node"})
    
    prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œè´Ÿè´£å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å°†ä»»åŠ¡åˆ†ç»™å…¶ä»–Agentæ‰§è¡Œã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å’Œæ—…æ¸¸è·¯çº¿è§„åˆ’ç›¸å…³çš„ï¼Œé‚£å°±è¿”å›travelã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›è®²ä¸€ä¸ªç¬‘è¯ï¼Œé‚£å°±è¿”å›jokeã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›å¯¹ä¸€ä¸ªå¯¹è”ï¼Œé‚£å°±è¿”å›coupletã€‚
        å¦‚æœæ˜¯å…¶ä»–çš„é—®é¢˜ï¼Œè¿”å›otherã€‚
        æ³¨æ„ï¼šåªè¿”å›ä¸Šè¿°å››ä¸ªå•è¯ä¸­çš„ä¸€ä¸ªï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–çš„å†…å®¹ã€‚
        """
    
    # ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†æ¶ˆæ¯å†…å®¹
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_content = state["messages"][-1].content
    else:
        user_content = str(state["messages"])
    
    print(f"ç”¨æˆ·é—®é¢˜: {user_content}")
    
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": user_content}
    ]
    
    # å¦‚æœå·²æœ‰typeå±æ€§ä¸”ä¸æ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­æ˜¯å¦å®Œæˆ
    if "type" in state and state["type"] in ["travel", "joke", "couplet", "other"]:
        # ä½¿ç”¨å¤§æ¨¡å‹åˆ¤æ–­ä»»åŠ¡æ˜¯å¦å®Œæˆ
        completion_prompt = f"""
        è¯·åˆ¤æ–­å½“å‰å¯¹è¯æ˜¯å¦å·²ç»å®Œæˆç”¨æˆ·çš„ä»»åŠ¡éœ€æ±‚ã€‚
        
        ç”¨æˆ·åŸå§‹è¯·æ±‚ï¼š
        {state['messages'][0].content if state['messages'] else 'æ— '}
        
        å½“å‰å¯¹è¯å†å²ï¼š
        {[msg.content for msg in state['messages']]}
        
        å½“å‰ä»»åŠ¡ç±»å‹ï¼š{state['type']}
        
        è¯·ä»”ç»†æ£€æŸ¥ç”¨æˆ·åŸå§‹è¯·æ±‚ä¸­æ˜¯å¦åŒ…å«å¤šä¸ªä»»åŠ¡è¦æ±‚ï¼Œç„¶åå›ç­”"å®Œæˆ"æˆ–"æœªå®Œæˆ"ï¼š
        - å¦‚æœç”¨æˆ·çš„æ‰€æœ‰ä»»åŠ¡è¦æ±‚éƒ½å·²ç»æ»¡è¶³ï¼Œå›ç­”"å®Œæˆ"
        - å¦‚æœç”¨æˆ·è¿˜æœ‰æœªå®Œæˆçš„ä»»åŠ¡è¦æ±‚ï¼Œå›ç­”"æœªå®Œæˆ"
        
        ç‰¹åˆ«æ³¨æ„ï¼šç”¨æˆ·å¯èƒ½åœ¨ä¸€ä¸ªè¯·æ±‚ä¸­è¦æ±‚å¤šä¸ªä»»åŠ¡ã€‚
        """
        
        completion_messages = [
            {"role": "system", "content": completion_prompt}
        ]
        
        completion_response = llm.invoke(completion_messages)
        completion_result = completion_response.content.strip()
        
        writer({"supervisor_step": f"ä»»åŠ¡å®ŒæˆçŠ¶æ€åˆ¤æ–­: {completion_result}"})
        
        if "å®Œæˆ" in completion_result:
            writer({"supervisor_step": f"ä»»åŠ¡å·²å®Œæˆï¼Œæµç¨‹ç»“æŸ"})
            return {"type": END}
        else:
            # åˆ¤æ–­ä¸‹ä¸€æ­¥æ‰§è¡Œå“ªä¸ªèŠ‚ç‚¹
            next_step_prompt = f"""
            æ ¹æ®ç”¨æˆ·åŸå§‹è¯·æ±‚å’Œå½“å‰è¿›å±•ï¼Œå†³å®šä¸‹ä¸€æ­¥åº”è¯¥æ‰§è¡Œå“ªä¸ªå¤„ç†èŠ‚ç‚¹ã€‚
            
            ç”¨æˆ·åŸå§‹è¯·æ±‚ï¼š
            {state['messages'][0].content if state['messages'] else 'æ— '}
            
            å½“å‰å¯¹è¯å†å²ï¼š
            {[msg.content for msg in state['messages']]}
            
            å½“å‰å·²å®Œæˆçš„ä»»åŠ¡ï¼š{state['type']}
            å¯ç”¨èŠ‚ç‚¹ï¼štravel, joke, couplet, other
            
            è¯·åˆ†æç”¨æˆ·è¿˜æœ‰å“ªäº›ä»»åŠ¡æ²¡æœ‰å®Œæˆï¼Œé€‰æ‹©æœ€åˆé€‚çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹ã€‚
            åªè¿”å›èŠ‚ç‚¹åç§°ï¼ˆtravel/joke/couplet/otherï¼‰
            """
            
            next_step_messages = [
                {"role": "system", "content": next_step_prompt}
            ]
            
            next_step_response = llm.invoke(next_step_messages)
            next_node = next_step_response.content.strip().lower()
            
            #æ‰“å°ä¿¡æ¯è°ƒè¯•
            writer({"supervisor_step": f"å¤§æ¨¡å‹å»ºè®®çš„ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {next_node}"})
            # ç¡®ä¿è¿”å›çš„èŠ‚ç‚¹åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­
            if next_node not in nodes:
                next_node = state["type"]  # é»˜è®¤ç»§ç»­å½“å‰ä»»åŠ¡
            
            writer({"supervisor_step": f"ç»§ç»­æ‰§è¡Œ: {next_node}"})
            return {"type": next_node}
    
    # é¦–æ¬¡æ‰§è¡Œï¼Œè¿›è¡Œä»»åŠ¡åˆ†ç±»
    response = llm.invoke(messages)
    typeRes = response.content.strip().lower()
    writer({"supervisor_step": f"é—®é¢˜åˆ†ç±»ç»“æœ: {typeRes}"})
    
    print(f"æ¨¡å‹è¿”å›ç±»å‹: '{typeRes}'")
    print(f"é¢„å®šä¹‰èŠ‚ç‚¹: {nodes}")
    
    # ä¿®æ­£ï¼šæ£€æŸ¥ç±»å‹æ˜¯å¦åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­
    if typeRes in nodes:
        print(f"âœ… ç±»å‹ '{typeRes}' åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­")
        return {"type": typeRes}
    else:
        print(f"âš ï¸  ç±»å‹ '{typeRes}' ä¸åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­ï¼Œä½¿ç”¨ 'other'")
        return {"type": "other"}
def travel_node(state: State):
    print(">>> travel_node")
    writer = get_stream_writer()
    writer({"node": "travel_node"})
    # å®é™…åº”è¯¥è°ƒç”¨æ—…æ¸¸ç›¸å…³çš„APIæˆ–å¤„ç†é€»è¾‘
    travel_response = "ä¸ºæ‚¨æ¨èæ¹–å—æ—…æ¸¸è·¯çº¿ï¼šé•¿æ²™->å¼ å®¶ç•Œ->å‡¤å‡°å¤åŸï¼Œå…¨ç¨‹5å¤©4æ™šã€‚"
    return {"messages": [AIMessage(content=travel_response)], "type": "travel"}

def joke_node(state: State):
    print(">>> joke_node")
    writer = get_stream_writer()
    writer({"node": "joke_node"})
    
    # æ›´è¯¦ç»†çš„æç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å–œå‰§ç¼–å‰§å’Œç¬‘è¯ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚åˆ›ä½œä¸€ä¸ªç²¾å½©çš„ç¬‘è¯ã€‚
    
    åˆ›ä½œæŒ‡å—ï¼š
    1. ç»“æ„å®Œæ•´ï¼šæœ‰é“ºå«ã€è½¬æŠ˜å’Œç¬‘ç‚¹
    2. è¯­è¨€ç”ŸåŠ¨ï¼šä½¿ç”¨å½¢è±¡çš„è¯­è¨€å’Œé€‚å½“çš„å¤¸å¼ 
    3. è´´è¿‘ç”Ÿæ´»ï¼šä»æ—¥å¸¸ç”Ÿæ´»ä¸­å¯»æ‰¾çµæ„Ÿ
    4. ç§¯æå‘ä¸Šï¼šé¿å…ä½ä¿—ã€æ­§è§†æ€§å†…å®¹
    5. é€‚åº¦åˆ›æ–°ï¼šå¯ä»¥ç»“åˆæ—¶äº‹çƒ­ç‚¹æˆ–æµè¡Œæ–‡åŒ–
    
    å¦‚æœç”¨æˆ·æŒ‡å®šäº†ç¬‘è¯ç±»å‹ï¼ˆå¦‚å†·ç¬‘è¯ã€ç›¸å£°æ®µå­ã€è°éŸ³æ¢—ç­‰ï¼‰ï¼Œè¯·æŒ‰ç…§è¦æ±‚åˆ›ä½œã€‚
    å¦‚æœç”¨æˆ·æåˆ°äº†å…·ä½“çš„å–œå‰§æ¼”å‘˜é£æ ¼ï¼ˆå¦‚éƒ­å¾·çº²ã€å‘¨ç«‹æ³¢ç­‰ï¼‰ï¼Œè¯·æ¨¡ä»¿ç›¸åº”çš„é£æ ¼ã€‚"""
    
    # è·å–ç”¨æˆ·è¾“å…¥
    #state["messages"] å­˜å‚¨äº†æ•´ä¸ªå¯¹è¯å†å²
    #state["messages"][-1] è·å–æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆé€šå¸¸æ˜¯ç”¨æˆ·çš„è¾“å…¥ï¼‰
    #é€šè¿‡ .content å±æ€§æå–æ¶ˆæ¯çš„æ–‡æœ¬å†…å®¹
    
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
        user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n\nè¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚åˆ›ä½œä¸€ä¸ªåˆé€‚çš„ç¬‘è¯ã€‚"
    else:
        user_prompt = "è¯·åˆ›ä½œä¸€ä¸ªæœ‰è¶£çš„ç¬‘è¯ï¼Œä¸»é¢˜ä¸é™ã€‚"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    writer({"joke_generation": "å¤§æ¨¡å‹æ­£åœ¨åˆ›ä½œç¬‘è¯..."})
    
    try:
        response = llm.invoke(messages)
        joke_content = response.content.strip()
        
        # ç¡®ä¿ç¬‘è¯å†…å®¹ä¸ä¸ºç©º
        if not joke_content:
            joke_content = "ä¸ºä»€ä¹ˆç¨‹åºå‘˜æ€»æ˜¯åˆ†ä¸æ¸…ä¸‡åœ£èŠ‚å’Œåœ£è¯èŠ‚ï¼Ÿå› ä¸º Oct 31 == Dec 25ï¼"
            
        writer({"generated_joke": joke_content})
        
    except Exception as e:
        writer({"error": f"ç¬‘è¯ç”Ÿæˆå¤±è´¥: {e}"})
        # å¤‡ç”¨ç¬‘è¯
        joke_content = "å¬è¯´æœ‰ä¸ªç¨‹åºå‘˜å»é’“é±¼ï¼Œé’“äº†ä¸€å¤©éƒ½æ²¡é’“åˆ°ã€‚åæ¥ä»–å‘ç°ï¼ŒåŸæ¥ä»–ä¸€ç›´åœ¨è°ƒçš„æ˜¯ debugã€‚ã€‚ã€‚"
    
    #æ‹¿åˆ°å¤§æ¨¡å‹æ€è€ƒç»“æœåï¼Œæ›´æ–°stateçŠ¶æ€
    #å¿…é¡»è¦HumanMessageæ–¹å¼è¿”å›ï¼Œä¸å¯ä»¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    #langchainä¸­æœ‰ä¸åŒæ¶ˆæ¯ç±»å‹ï¼š
    return {"messages": [AIMessage(content=joke_content)], "type": "joke"}

def couplet_node(state: State):
    print(">>> couplet_node")
    writer = get_stream_writer()
    writer({"node": "couplet_node"})
    # å®é™…åº”è¯¥è°ƒç”¨å¯¹è”ç”ŸæˆAPI
    
    system_prompt="""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¯¹è”ç”Ÿæˆå™¨ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚åˆ›ä½œä¸€ä¸ªç²¾å½©çš„å¯¹è”
    """
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_input = state["messages"][-1].content
        user_prompt = f"ç”¨æˆ·è¯·æ±‚ï¼š{user_input}\n\nè¯·æ ¹æ®ä»¥ä¸Šè¦æ±‚åˆ›ä½œä¸€ä¸ªç²¾å½©çš„å¯¹è”ã€‚"
    else:
        user_prompt = "è¯·åˆ›ä½œä¸€ä¸ªæœ‰è¶£çš„å¯¹è”ï¼Œä¸»é¢˜ä¸é™ã€‚"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    writer({"joke_generation": "å¤§æ¨¡å‹æ­£åœ¨åˆ›ä½œå¯¹è”..."})
    
    try:
        response = llm.invoke(messages)
        couplet_content = response.content.strip()
        
        # ç¡®ä¿å¯¹è”å†…å®¹ä¸ä¸ºç©º
        if not couplet_content:
            couplet_content = "é»˜è®¤å¯¹è”"
            
        writer({"generated_joke": couplet_content})
        
    except Exception as e:
        writer({"error": f"å¯¹è”ç”Ÿæˆå¤±è´¥: {e}"})
        # å¤‡ç”¨ç¬‘è¯
        couplet_content = "å‡†å¤‡å¥½çš„å¯¹è”"
    
    #æ‹¿åˆ°å¤§æ¨¡å‹æ€è€ƒç»“æœåï¼Œæ›´æ–°stateçŠ¶æ€
    #å¿…é¡»è¦HumanMessageæ–¹å¼è¿”å›ï¼Œä¸å¯ä»¥ç›´æ¥è¿”å›å­—ç¬¦ä¸²
    #langchainä¸­æœ‰ä¸åŒæ¶ˆæ¯ç±»å‹ï¼š
    return {"messages": [AIMessage(content=couplet_content)], "type": "couplet"}


def other_node(state: State):
    print(">>> other_node")
    writer = get_stream_writer()
    writer({"node": "other_node"})
    other_response = "æˆ‘ä¸»è¦æ“…é•¿æ—…æ¸¸è§„åˆ’ã€è®²ç¬‘è¯å’Œå¯¹å¯¹è”ï¼Œæ‚¨çš„é—®é¢˜æš‚æ—¶æ— æ³•å›ç­”ã€‚"
    return {"messages": [HumanMessage(content=other_response)], "type": "other"}

def routing_func(state: State):
    print(f"è·¯ç”±å‡½æ•°æ¥æ”¶åˆ°ç±»å‹: {state['type']}")
    
    if state["type"] == "travel":
        return "travel_node"
    elif state["type"] == "joke":
        return "joke_node"
    elif state["type"] == "couplet":
        return "couplet_node"
    elif state["type"] == "other":
        return "other_node"
    elif state["type"] == END:
        return END
    else:
        print(f"âŒ æœªçŸ¥ç±»å‹: {state['type']}ï¼Œè·¯ç”±åˆ° other_node")
        return "other_node"

# æ„å»ºå›¾
builder = StateGraph(State)
builder.add_node("supervisor_node", supervisor_node)
builder.add_node("travel_node", travel_node)
builder.add_node("joke_node", joke_node)
builder.add_node("couplet_node", couplet_node)
builder.add_node("other_node", other_node)

# è®¾ç½®æµç¨‹
builder.add_edge(START, "supervisor_node")

# æ¡ä»¶è·¯ç”±ï¼Œlanggraphæ‰§è¡Œå¼•æ“ï¼Œå¦‚æœè¿”å›å€¼ä¸ºjoke_nodeåˆ™ä¸‹ä¸€ä¸ªæ‰§è¡Œä»»åŠ¡çš„æ˜¯joke_node
builder.add_conditional_edges(
    "supervisor_node",
    routing_func,
    {
        "travel_node": "travel_node",
        "joke_node": "joke_node", 
        "couplet_node": "couplet_node",
        "other_node": "other_node",
        END: END
    }
)

# å„ä¸ªå¤„ç†èŠ‚ç‚¹å®Œæˆåå›åˆ° supervisor_node è¿›è¡Œç»“æœç¡®è®¤
builder.add_edge("travel_node", "supervisor_node")
builder.add_edge("joke_node", "supervisor_node") 
builder.add_edge("couplet_node", "supervisor_node")
builder.add_edge("other_node", "supervisor_node")

checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)

if __name__ == "__main__":
    config = {"configurable": {"thread_id": "1"}}
    
    # ä¿®æ­£ï¼šè¾“å…¥åº”è¯¥æ˜¯ HumanMessage å¯¹è±¡åˆ—è¡¨
    input_data = {
        "messages": [HumanMessage(content="ä»Šå¤©å¤©æ°”å¦‚ä½•")]
    }
    
    print("å¼€å§‹æ‰§è¡Œå¤šAgentæµç¨‹...")
    # try:
    #     for chunk in graph.stream(
    #         input_data,
    #         config=config,
    #         stream_mode="values"
    #     ):
    #         node_name = list(chunk.keys())[0] if chunk else "unknown"
    #         print(f"=== èŠ‚ç‚¹ {node_name} è¾“å‡º ===")
    #         print(chunk)
    #         print("=" * 50)
    # except Exception as e:
    #     print(f"æ‰§è¡Œå‡ºé”™: {e}")
    #     import traceback
    #     traceback.print_exc()
    res = graph.invoke({"message":["è¯´ä¸ªç¬‘è¯"]}
                       ,config
                       ,stream_mode="values")
    print(res["messages"][-1].content)
    