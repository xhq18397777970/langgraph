from operator import add
from dotenv import load_dotenv
from typing import TypedDict, Annotated
from langchain_core.messages import AnyMessage
from langgraph.graph import START, END
from langgraph.graph import StateGraph
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import MemorySaver
import os
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from config.model_config import get_deepseek_model

# å®šä¹‰æ—¥å¿—å‡½æ•°
def get_stream_writer():
    """ç®€å•çš„æµå¼è¾“å‡ºå†™å…¥å™¨"""
    def writer(data):
        if isinstance(data, dict):
            print(f"ğŸ“Š {data}")
        else:
            print(f"ğŸ”” {data}")
    return writer

load_dotenv()

# ä¿®æ­£ï¼šnodes åº”è¯¥ä¸æ¨¡å‹è¿”å›çš„ç±»å‹ä¸€è‡´
nodes = ["travel", "joke", "couplet", "other"]
llm = get_deepseek_model()

class State(TypedDict):
    messages: Annotated[list[AnyMessage], add]
    type: str

def supervisor_node(state: State):
    print(">>> supervisor_node")
    writer = get_stream_writer()
    writer({"node": "supervisor_node"})
    
    prompt = """
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œè´Ÿè´£å¯¹ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œåˆ†ç±»ï¼Œå¹¶å°†ä»»åŠ¡åˆ†ç»™å…¶ä»–Agentæ‰§è¡Œã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å’Œæ—…æ¸¸è·¯çº¿è§„åˆ’ç›¸å…³çš„ï¼Œé‚£å°±è¿”å›travelã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›è®²ä¸€ä¸ªç¬‘è¯ï¼Œé‚£å°±è¿”å›jokeã€‚
        å¦‚æœç”¨æˆ·çš„é—®é¢˜æ˜¯å¸Œæœ›å¯¹ä¸€ä¸ªå¯¹è”ï¼Œé‚£å°±è¿”å›coupletã€‚
        å¦‚æœæ˜¯å…¶ä»–çš„é—®é¢˜ï¼Œè¿”å›otherã€‚
        æ³¨æ„ï¼šåªè¿”å›ä¸Šè¿°å››ä¸ªå•è¯ä¸­çš„ä¸€ä¸ªï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–çš„å†…å®¹ã€‚
        """
    
    # ä¿®æ­£ï¼šæ­£ç¡®å¤„ç†æ¶ˆæ¯å†…å®¹
    if state["messages"] and hasattr(state["messages"][-1], 'content'):
        user_content = state["messages"][-1].content
    else:
        user_content = str(state["messages"])
    
    print(f"ç”¨æˆ·é—®é¢˜: {user_content}")
    
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": user_content}
    ]
    
    # å¦‚æœå·²æœ‰typeå±æ€§ä¸”ä¸æ˜¯ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼Œè¡¨ç¤ºé—®é¢˜å·²ç»å¤„ç†å®Œæˆ
    if "type" in state and state["type"] in ["travel", "joke", "couplet", "other"]:
        writer({"supervisor_step": f"å·²è·å¾— {state['type']} æ™ºèƒ½ä½“å¤„ç†ç»“æœï¼Œæµç¨‹ç»“æŸ"})
        return {"type": END}
    
    response = llm.invoke(messages)
    typeRes = response.content.strip().lower()
    writer({"supervisor_step": f"é—®é¢˜åˆ†ç±»ç»“æœ: {typeRes}"})
    
    print(f"æ¨¡å‹è¿”å›ç±»å‹: '{typeRes}'")
    print(f"é¢„å®šä¹‰èŠ‚ç‚¹: {nodes}")
    
    # ä¿®æ­£ï¼šæ£€æŸ¥ç±»å‹æ˜¯å¦åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­
    if typeRes in nodes:
        print(f"âœ… ç±»å‹ '{typeRes}' åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­")
        return {"type": typeRes}
    else:
        print(f"âš ï¸  ç±»å‹ '{typeRes}' ä¸åœ¨é¢„å®šä¹‰èŠ‚ç‚¹ä¸­ï¼Œä½¿ç”¨ 'other'")
        return {"type": "other"}

def travel_node(state: State):
    print(">>> travel_node")
    writer = get_stream_writer()
    writer({"node": "travel_node"})
    # å®é™…åº”è¯¥è°ƒç”¨æ—…æ¸¸ç›¸å…³çš„APIæˆ–å¤„ç†é€»è¾‘
    travel_response = "ä¸ºæ‚¨æ¨èæ¹–å—æ—…æ¸¸è·¯çº¿ï¼šé•¿æ²™->å¼ å®¶ç•Œ->å‡¤å‡°å¤åŸï¼Œå…¨ç¨‹5å¤©4æ™šã€‚"
    return {"messages": [HumanMessage(content=travel_response)], "type": "travel"}

def joke_node(state: State):
    print(">>> joke_node")
    writer = get_stream_writer()
    writer({"node": "joke_node"})
    # å®é™…åº”è¯¥è°ƒç”¨ç¬‘è¯ç”ŸæˆAPIæˆ–ä»æ•°æ®åº“è·å–ç¬‘è¯
    joke_content = "éƒ­å¾·çº²è¯´è¿‡ï¼š'æˆ‘å°å­¦åå¹´ï¼Œä¸­å­¦åäºŒå¹´ï¼Œæˆ‘è¢«è¯„ä¸ºå…¨æ ¡æœ€ç†Ÿæ‚‰çš„é¢å­”ï¼Œæ–°è€å¸ˆæ¥äº†éƒ½è·Ÿæˆ‘æ‰“å¬å­¦æ ¡å†…å¹•ã€‚'"
    return {"messages": [HumanMessage(content=joke_content)], "type": "joke"}

def couplet_node(state: State):
    print(">>> couplet_node")
    writer = get_stream_writer()
    writer({"node": "couplet_node"})
    # å®é™…åº”è¯¥è°ƒç”¨å¯¹è”ç”ŸæˆAPI
    couplet_response = "ä¸Šè”ï¼šæ˜¥é£å¾—æ„é©¬è¹„ç–¾ï¼Œä¸‹è”ï¼šæ—­æ—¥æ‰¬è¾‰å…‰ç…§å¼º"
    return {"messages": [HumanMessage(content=couplet_response)], "type": "couplet"}

def other_node(state: State):
    print(">>> other_node")
    writer = get_stream_writer()
    writer({"node": "other_node"})
    other_response = "æˆ‘ä¸»è¦æ“…é•¿æ—…æ¸¸è§„åˆ’ã€è®²ç¬‘è¯å’Œå¯¹å¯¹è”ï¼Œæ‚¨çš„é—®é¢˜æš‚æ—¶æ— æ³•å›ç­”ã€‚"
    return {"messages": [HumanMessage(content=other_response)], "type": "other"}

def routing_func(state: State):
    print(f"è·¯ç”±å‡½æ•°æ¥æ”¶åˆ°ç±»å‹: {state['type']}")
    
    if state["type"] == "travel":
        return "travel_node"
    elif state["type"] == "joke":
        return "joke_node"
    elif state["type"] == "couplet":
        return "couplet_node"
    elif state["type"] == "other":
        return "other_node"
    elif state["type"] == END:
        return END
    else:
        print(f"âŒ æœªçŸ¥ç±»å‹: {state['type']}ï¼Œè·¯ç”±åˆ° other_node")
        return "other_node"

# æ„å»ºå›¾
builder = StateGraph(State)
builder.add_node("supervisor_node", supervisor_node)
builder.add_node("travel_node", travel_node)
builder.add_node("joke_node", joke_node)
builder.add_node("couplet_node", couplet_node)
builder.add_node("other_node", other_node)

# è®¾ç½®æµç¨‹
builder.add_edge(START, "supervisor_node")

# æ¡ä»¶è·¯ç”±ï¼Œlanggraphæ‰§è¡Œå¼•æ“ï¼Œå¦‚æœè¿”å›å€¼ä¸ºjoke_nodeåˆ™ä¸‹ä¸€ä¸ªæ‰§è¡Œä»»åŠ¡çš„æ˜¯joke_node
builder.add_conditional_edges(
    "supervisor_node",
    routing_func,
    {
        "travel_node": "travel_node",
        "joke_node": "joke_node", 
        "couplet_node": "couplet_node",
        "other_node": "other_node",
        END: END
    }
)

# å„ä¸ªå¤„ç†èŠ‚ç‚¹å®Œæˆåå›åˆ° supervisor_node è¿›è¡Œç»“æœç¡®è®¤
builder.add_edge("travel_node", "supervisor_node")
builder.add_edge("joke_node", "supervisor_node") 
builder.add_edge("couplet_node", "supervisor_node")
builder.add_edge("other_node", "supervisor_node")

checkpointer = MemorySaver()
graph = builder.compile(checkpointer=checkpointer)

if __name__ == "__main__":
    config = {"configurable": {"thread_id": "1"}}
    
    # ä¿®æ­£ï¼šè¾“å…¥åº”è¯¥æ˜¯ HumanMessage å¯¹è±¡åˆ—è¡¨
    input_data = {
        "messages": [HumanMessage(content="ç»™æˆ‘è®²ä¸€ä¸ªéƒ­å¾·çº²çš„ç¬‘è¯")]
    }
    
    print("å¼€å§‹æ‰§è¡Œå¤šAgentæµç¨‹...")
    try:
        for chunk in graph.stream(
            input_data,
            config=config,
            stream_mode="values"
        ):
            node_name = list(chunk.keys())[0] if chunk else "unknown"
            print(f"=== èŠ‚ç‚¹ {node_name} è¾“å‡º ===")
            print(chunk)
            print("=" * 50)
    except Exception as e:
        print(f"æ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()